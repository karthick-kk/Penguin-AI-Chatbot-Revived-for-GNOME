<schemalist gettext-domain="gnome-shell-extensions">
  <schema id="org.gnome.shell.extensions.penguin-ai-chatbot"
      path="/org/gnome/shell/extensions/penguin-ai-chatbot/">



    <key name="llm-provider" type="s">
        <default>'anthropic'</default>
        <summary>LLM provider</summary>
    </key>



    <key name="anthropic-api-key" type="s">
        <default>''</default>
        <summary>Anthropic API Key</summary>
        <description>Your Anthropic API key. Required to use Anthropic models.</description>
    </key>
    <key name="openai-api-key" type="s">
        <default>''</default>
        <summary>OpenAI API Key</summary>
        <description>Your OpenAI API key. Required to use OpenAI models.</description>
    </key>
    <key name="gemini-api-key" type="s">
        <default>''</default>
        <summary>Gemini API Key</summary>
        <description>Your Gemini API key. Required to use Gemini models.</description>
    </key>
    <key name="openrouter-api-key" type="s">
        <default>''</default>
        <summary>Open Router API Key</summary>
        <description>Your Open Router API key. Required to use Open Router models.</description>
    </key>



    <key name="anthropic-model" type="s">
        <default>'claude-3-sonnet-20240229'</default>
        <summary>Anthropic Model</summary>
        <description>The Anthropic model to use for chat.</description>
    </key>
    <key name="openai-model" type="s">
        <default>'gpt-4o'</default>
        <summary>OpenAI Model</summary>
        <description>The OpenAI model to use for chat.</description>
    </key>
    <key name="openrouter-model" type="s">
        <default>'meta-llama/llama-3.3-70b-instruct:free'</default>
        <summary>OpenRouter model</summary>
        <description>The OpenRouter model to use for chat.</description>
    </key>
    <key name="gemini-model" type="s">
        <default>'gemini-2.0-flash'</default>
        <summary>Gemini Model</summary>
        <description>The Gemini model to use for chat.</description>
    </key>
    <key name="ollama-model" type="s">
        <default>''</default>
        <summary>Ollama model name</summary>
    </key>

    <key name="request-timeout" type="i">
        <default>300</default>
        <summary>Request timeout in seconds</summary>
        <description>Timeout for LLM API requests in seconds. Increase for slower models or reasoning models that take longer to respond.</description>
    </key>



    <key name="history" type="s">
        <default>'[]'</default>
        <summary>Chat History</summary>
        <description>Stores the chat history as a JSON string.</description>
    </key>



    <key name="human-message-color" type="s">
        <default>'rgb(0, 106, 255)'</default>
        <summary>Your Message Background Color</summary>
        <description>The background color for your messages.</description>
    </key>
    <key name="llm-message-color" type="s">
        <default>'rgb(96,99,102)'</default>
        <summary>Chatbot Message Background Color</summary>
        <description>The background color for the chatbot's messages.</description>
    </key>
    <key name="llm-message-text-color" type="s">
        <default>'rgb(255,255,255)'</default>
        <summary>Chatbot Message Text Color</summary>
        <description>The text color for the chatbot's messages.</description>
    </key>
    <key name="human-message-text-color" type="s">
        <default>'rgb(255,255,255)'</default>
        <summary>Your Message Text Color</summary>
        <description>The text color for your messages.</description>
    </key>
    <key name="open-chat-shortcut" type="as">
      <default><![CDATA[['<Super>l']]]></default>
      <summary>Shortcut to open the chat window</summary>
      <description>
        Keyboard shortcut to open the chat window.
      </description>
    </key>
  </schema>
</schemalist>
